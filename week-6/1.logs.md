---
theme: gaia
_class: lead
paginate: true
backgroundColor: #fff
backgroundImage: url('https://marp.app/assets/hero-background.svg')
marp: true
---

![bg left:40% 80%](https://raw.githubusercontent.com/kubernetes/kubernetes/master/logo/logo.svg)

# **Kubernetes Projects**

러닝스푼즈
Kubernetes Deep Dive - 6주차 - 1

---

# 목차

1. Observability
2. Conclusion
3. Discussion

---

# 저번주에 뭐했죠?

https://www.notion.so/c691f717a82b422da99e09fdff41d58e

---

# Observability

애플리케이션을 모니터링하는 방법은?

---

# Observability

애플리케이션을 모니터링하는 방법은?

1. Logging
2. Metric
3. Tracing
4. Continuous Profiling

---

# Observability

애플리케이션을 모니터링하는 방법은?
(위에서 아래로 순차적으로 가게됩니다.)

1. Logging
2. Metric
3. Tracing
4. Continuous Profiling

---

# Observability

애플리케이션을 모니터링하는 방법은?
(위에서 아래로 순차적으로 가게됩니다.) ~~(가고싶지 않아도)~~

1. Logging
2. Metric
3. Tracing
4. Continuous Profiling

---

# Logging

---

# Logging

정의: 애플리케이션의 STDOUT 혹은 STDERR 로 출력된 문자열
고민: 수십 개의 Pod에서 나온 로그를 어떻게 보면 좋을까?

---

# Logging: 답변

답변 - 1 : Kubernetes API 를 잘 사용하자.

```bash
# 랜덤으로 Pod 하나 골라서 로그 보기
kubectl logs deployments/blue-app

# 라벨 일치하는거 전부 보기
kubectl logs -l app=blue

# 최근 로그만 보기
kubectl logs some-pod --since 1s -f

# 왜 죽었는지 보기
kubectl logs some-pod --previous
```

---

# Logging: 답변

답변 - 2 : Kubernetes API 를 잘 사용하는 툴을 쓰자

```bash
stern somepod
stern somepod -o raw | jq
```

---

# 한계점

부하 큼. 실시간으로 밖에 못 봄.

`client -http-> kube-apiserver -http-> kubelet -> file`

---

# Cluster-Level Logging

- 클러스터 관점으로 로그를 로그 저장소에 저장

---

# Cluster-Level Logging

- 클러스터 관점으로 로그를 로그 저장소에 저장
- 두 가지 접근법
  - Side Car
  - Node Agent

---

# Cluster-Level Logging - [Sidecar](https://kubernetes.io/docs/concepts/cluster-administration/logging/#sidecar-container-with-a-logging-agent)

![Alt text](https://d33wubrfki0l68.cloudfront.net/d55c404912a21223392e7d1a5a1741bda283f3df/c0397/images/docs/user-guide/logging/logging-with-sidecar-agent.png)

- 장점: 특이한 요구사항 맞추기 좋다.
- 단점: 그 이외의 모든 것
  [설정이 귀찮다. {예외 상황에 대한 고민을 해줘야 한다. (강제종료시, 메모리관리, 디스크 관리 등등)}]

---

# Cluster-Level Logging - [Node Agent](https://kubernetes.io/docs/concepts/cluster-administration/logging/#cluster-level-logging-architectures)

![Alt text](https://d33wubrfki0l68.cloudfront.net/2585cf9757d316b9030cf36d6a4e6b8ea7eedf5a/1509f/images/docs/user-guide/logging/logging-with-node-agent.png)

- 장점: 설정이 편하다.
- 단점: [특이 케이스 핸들링](https://github.com/kubernetes/kubernetes/issues/110630)이 좀 까다로웠다. ([1.28](https://github.com/kubernetes/kubernetes/blob/v1.28.7/pkg/kubelet/logs/container_log_manager.go#L42-L44), [1.30?](https://github.com/kubernetes/kubernetes/pull/114301))

---

# Cluster-Level Logging - 원리

- kubelet 이 [CRI 를 통해서 컨테이너를 실행할때 로그 경로를 미리 지정](https://github.com/kubernetes/cri-api/blob/1fb4dbdc9cbf5673c5c6ac7145d5269b78140a4b/pkg/apis/runtime/v1/api.proto#L1069-L1074)한다.
- 이 경로는 `/var/log/pod`로 이 [값](https://github.com/kubernetes/kubernetes/pull/74441)은 [하드코딩](https://github.com/kubernetes/kubernetes/blob/release-1.27/pkg/kubelet/kuberuntime/kuberuntime_manager.go#L73) 되어있다.
- `fluentd`, `filebeat`, `vector`, `promtail` 등의 로그 수집기들은 이 경로상에 존재하는 로그를 긁어간다.
- `Elasticsearch`, `Loki`, `Datadog` 등의 방법으로 바로 인덱싱하던가
- or `Kafka`, `fluentd` 등의 버퍼를 두고 주기성을 가지고 인덱싱한다.
- 부르는 명칭은 다양하지만 보통 다음과 같이 아키텍처를 구현

---

![bg 70%](https://dytvr9ot2sszz.cloudfront.net/wp-content/uploads/2018/06/kuberbetes-monitoring-arch-1.jpg)
[ref](https://logz.io/blog/fluentd-vs-fluent-bit/)
[plus](https://dailychat.io/conversation/3e043fda-76df-40ac-b70e-60b5fd717d86)

---

# Cluster-Level Logging - 유명한 것

1. Elasticsearch w/ fluentd or filebeat

- 전통적인 강자 / 빠르고 무거움 / 사용하기 편함 / 운영하기는 전문적인 지식이 필요하고 까다로움

2. Splunk

- 무겁고 / 어렵고 / 비쌈

3. Loki

- 신흥 강자 / 제약사항이 있지만 가벼움 / S3 를 스토리지로 활용 / Kubernetes 친화적

---

# Cluster-Level Logging - 유명한 것

4. Datadog

- 운용 인력이 없으면 돈으로 해결 가능한 모니터링 솔루션 (상당히 비쌈)

5. New Relic

- 운용 인력이 없으면 돈으로 해결 가능한 모니터링 솔루션 (Datadog 보다 상당히 저렴)

6. Dynatrace

- 후기 부재
