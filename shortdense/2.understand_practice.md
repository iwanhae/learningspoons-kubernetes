---
theme: gaia
_class: lead
paginate: true
backgroundColor: #fff
backgroundImage: url('https://s3.iwanhae.kr/public/bg.png')
marp: true
style: |
  section::after {
    left: 0;
    right: 0;
    top: 0;
    text-align: left;
  }
---

![bg left:40% 80%](https://raw.githubusercontent.com/kubernetes/kubernetes/master/logo/logo.svg)

# **Kubernetes Controller**

러닝스푼즈
Kubernetes Deep Dive - 2주차 - 3교시

---

3. Pod Lifecycle (실습)

---

3-1. Request 와 Limit > QoS Class
3-2. Pod, EndPoint, (+ VolumeAttachment ?)
3-3. ReadinessProbe 와 LivenessProbe
3-4. GracefulShutdown
(+ 3-5. Pod Disruption / Priority ?)

---

# CPU / MEM - Requests

- 리눅스입장에서는 CGroup 에 걸려있는 설정
- CPU 의 경우
  - CPU 스케줄러에 설정이 반영됨
  - 우선순위에 영향
- Mem 의 경우
  - OOM Score 에 영향

---

# CPU / MEM - Limits

- 리눅스입장에서는 CGroup 에 걸려있는 설정

---

# CPU / MEM - Limits

- 리눅스입장에서는 CGroup 에 걸려있는 설정
- CPU 의 경우
  - CPU 스케줄러에 설정이 반영됨
  - [좋은 참고자료](https://www.uber.com/en-KR/blog/avoiding-cpu-throttling-in-a-containerized-environment/)
  - 굉장히 구현하기 어려운 기능이고 비교적 최근(~ 4.10)까지 버그가 상당했음

---

# CPU / MEM - Limits

- 리눅스입장에서는 CGroup 에 걸려있는 설정
- Mem 의 경우
  - 운영체제가 가상메모리 할당할 때 영향
  - 주어진 범위가 벗어날때 CGroup OOM Killed 해버림 (-> K8s 에 이벤트 안남을 수 있음)
  - Limit 이 없으면 Node OOM Killed 라고 편의상 부름 (-> K8s 에 이벤트 안남음)

---

실습: https://github.com/iwanhae/simple-loadtester/blob/main/server/main.go#L67-L104

---

문제상황

---

# Pod 이 생성될 때 영향 받는것

1. Pod
2. PodIP
3. Endpoint (Service 가 있으면)

---

# Endpoint

1. Service 는 로드밸런서 (다음주에 자세히 다룰 예정)
2. Service 에 속해있는 실제 멤버를 알려주는 리소스
3. 대부분의 Ingress 구현체들은 ClusterIP 가 아닌 Endpoint 를 보고 PodIP 를 다이렉트로 찌름

---

# Endpoint 문제점

1. Pod 이 추가되거나 삭제될때 Endpoint 에 반영되고
2. Endpoint 에 반영된 내용이 실제 kube-proxy / ingress-nginx / traefik 등에 반영되는데 시간딜레이가 존재
3. 평균 수백 ms / 최대 30초 미만으로 긴편은 아니지만 서비스 순단을 만들기에는 충분

---

참고: https://stupendous-purple-c9f.notion.site/Pod-de77b3f616d04cec8a0fe32f088b263f
